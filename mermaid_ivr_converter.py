"""
PRODUCTION-READY Mermaid to IVR Converter
Fixed to use REAL database and generate proper IVR code following allflows LITE patterns
Addresses all issues identified by Andres
ENHANCED with ARCOS voice database integration
"""

import re
import csv
import json
import requests
import streamlit as st
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass
from enum import Enum
from difflib import SequenceMatcher

class NodeType(Enum):
    WELCOME = "welcome"
    DECISION = "decision" 
    ACTION = "action"
    PIN_ENTRY = "pin_entry"
    RESPONSE = "response"
    GOODBYE = "goodbye"
    ERROR = "error"
    SLEEP = "sleep"
    AVAILABILITY = "availability"

@dataclass
class VoiceFile:
    company: str
    folder: str
    file_name: str
    transcript: str
    callflow_id: str

class ProductionIVRConverter:
    def __init__(self, uploaded_csv_file=None):
        # Real voice file database (8,555 entries)
        self.voice_files: List[VoiceFile] = []
        self.transcript_index: Dict[str, List[VoiceFile]] = {}
        self.exact_match_index: Dict[str, VoiceFile] = {}
        
        # Load the database - either from uploaded file or fallback
        if uploaded_csv_file:
            self._load_database_from_upload(uploaded_csv_file)
        else:
            self._load_real_database()

    def _load_database_from_upload(self, uploaded_file):
        """Load database from uploaded cf_general_structure.csv file - ENHANCED with ARCOS integration"""
        try:
            print(f"üì• Loading database from uploaded file: {uploaded_file.name}")
            
            # Read the uploaded CSV file
            import io
            content = uploaded_file.read()
            
            # Handle both bytes and string content
            if isinstance(content, bytes):
                content = content.decode('utf-8')
            
            # Parse CSV content
            csv_reader = csv.DictReader(io.StringIO(content))
            
            # Debug: Check column names
            fieldnames = csv_reader.fieldnames
            print(f"üìã CSV columns found: {fieldnames}")
            
            row_count = 0
            arcos_entries = 0
            
            for row in csv_reader:
                row_count += 1
                
                # Extract callflow ID from file name (e.g., "1677.ulaw" ‚Üí "1677")
                file_name = row.get('File Name', row.get('file_name', ''))
                callflow_id = self._extract_callflow_id(file_name)
                
                company = row.get('Company', row.get('company', ''))
                
                voice_file = VoiceFile(
                    company=company,
                    folder=row.get('Folder', row.get('folder', '')),
                    file_name=file_name,
                    transcript=row.get('Transcript', row.get('transcript', '')),
                    callflow_id=callflow_id
                )
                self.voice_files.append(voice_file)
                
                # Count ARCOS entries
                if company.lower() == 'arcos':
                    arcos_entries += 1
                
                # Debug first few entries
                if row_count <= 5:
                    print(f"üìù Sample entry {row_count}: {voice_file.transcript[:50]} -> {callflow_id}")
            
            # Build search indexes
            self._build_indexes()
            print(f"‚úÖ Successfully loaded {len(self.voice_files)} voice files from uploaded CSV")
            print(f"üéØ ARCOS entries loaded: {arcos_entries}")
            print(f"üìà Expected improvement: {arcos_entries > 100}")
            
            # Verify we have key common phrases and ARCOS integration
            self._verify_database_content()
            
            # ENHANCED: Verify ARCOS integration if we have enough ARCOS entries
            if arcos_entries > 100:
                self._verify_arcos_integration()
            
        except Exception as e:
            print(f"‚ùå Failed to load uploaded database: {e}")
            print("üîÑ Falling back to remote database...")
            self._load_real_database()

    def _verify_arcos_integration(self):
        """NEW: Verify ARCOS voice files are properly integrated"""
        print(f"\nüîç ARCOS INTEGRATION VERIFICATION:")
        
        # Key phrases from ARCOS CSV that should dramatically improve matching
        expected_arcos_phrases = [
            ("press 1 if this is", "1002"),
            ("invalid entry. please try again", "1009"), 
            ("to the phone", "1006"),
            ("is not home", "1004"),
            ("press 3 if you need more time to get", "1005"),
            ("please enter your four digit pin", "1008"),
            ("automated voice response system", "1001")
        ]
        
        arcos_found = 0
        arcos_files = [vf for vf in self.voice_files if vf.company.lower() == 'arcos']
        
        for phrase, expected_id in expected_arcos_phrases:
            matches = [vf for vf in arcos_files if phrase.lower() in vf.transcript.lower()]
            if matches:
                arcos_found += 1
                best_match = matches[0]
                print(f"‚úÖ ARCOS: '{phrase}' -> {best_match.callflow_id}")
            else:
                print(f"‚ùå ARCOS: '{phrase}' NOT found")
        
        integration_score = (arcos_found / len(expected_arcos_phrases)) * 100
        print(f"\nüìä ARCOS Integration Score: {integration_score:.1f}%")
        
        if integration_score >= 80:
            print("üéØ Excellent ARCOS integration - expect 80%+ voice match rates!")
        elif integration_score >= 50:
            print("‚úÖ Good ARCOS integration - significant improvement expected")
        else:
            print("‚ö†Ô∏è Limited ARCOS integration - check CSV file format")
        
        return integration_score >= 50

    def _verify_database_content(self):
        """Verify database has expected content and show examples"""
        print(f"\nüîç DATABASE VERIFICATION:")
        print(f"üìä Total voice files: {len(self.voice_files)}")
        
        # Check for common phrases we expect to find
        common_phrases = [
            "this is an", "electric", "callout", "press 1", "press 3", 
            "thank you", "goodbye", "invalid", "available", "work"
        ]
        
        found_phrases = []
        
        for phrase in common_phrases:
            matches = [vf for vf in self.voice_files if phrase.lower() in vf.transcript.lower()]
            if matches:
                found_phrases.append(phrase)
                # Show first match
                best_match = min(matches, key=lambda x: len(x.transcript))
                print(f"‚úÖ '{phrase}' found: '{best_match.transcript}' -> {best_match.callflow_id}")
            else:
                print(f"‚ùå '{phrase}' NOT found in database")
        
        print(f"\nüìà SUMMARY: Found {len(found_phrases)}/{len(common_phrases)} common phrases")
        
        # Show transcript length distribution
        single_letters = [vf for vf in self.voice_files if len(vf.transcript.strip()) == 1]
        complete_words = [vf for vf in self.voice_files if 2 <= len(vf.transcript.strip()) <= 10]
        phrases = [vf for vf in self.voice_files if len(vf.transcript.strip()) > 10]
        
        print(f"\nüìè CONTENT ANALYSIS:")
        print(f"  Single letters: {len(single_letters)} files")
        print(f"  Complete words: {len(complete_words)} files") 
        print(f"  Phrases: {len(phrases)} files")
        
        return len(found_phrases) >= len(common_phrases) * 0.7

    def _load_real_database(self):
        """Load the actual cf_general_structure.csv with 8,555 voice files"""
        try:
            # Get CSV URL from secrets
            csv_url = st.secrets.get("csv_url", "")
            if not csv_url:
                raise ValueError("CSV URL not found in secrets")
            
            print(f"üì• Loading database from: {csv_url}")
            
            # Download and parse CSV
            response = requests.get(csv_url)
            response.raise_for_status()
            
            # Parse CSV content
            csv_content = response.text
            csv_reader = csv.DictReader(csv_content.splitlines())
            
            for row in csv_reader:
                # Extract callflow ID from file name (e.g., "1677.ulaw" ‚Üí "1677")
                file_name = row['File Name']
                callflow_id = self._extract_callflow_id(file_name)
                
                voice_file = VoiceFile(
                    company=row['Company'],
                    folder=row['Folder'],
                    file_name=file_name,
                    transcript=row['Transcript'],
                    callflow_id=callflow_id
                )
                self.voice_files.append(voice_file)
            
            # Build search indexes
            self._build_indexes()
            print(f"‚úÖ Loaded {len(self.voice_files)} real voice files from database")
            
        except Exception as e:
            print(f"‚ùå Failed to load real database: {e}")
            print("üîÑ Loading enhanced fallback database...")
            self._load_enhanced_fallback()

    def _load_enhanced_fallback(self):
        """Load enhanced fallback with common IVR phrases"""
        print("üìö Loading enhanced fallback database...")
        
        # Enhanced fallback with more realistic voice files
        enhanced_voice_data = [
            # Core phrases from allflows LITE
            ("arcos", "callflow", "1677.ulaw", "This is an", "1677"),
            ("arcos", "callflow", "1191.ulaw", "This is an", "1191"),
            ("arcos", "callflow", "1274.ulaw", "callout", "1274"),
            ("arcos", "callflow", "1589.ulaw", "from", "1589"),
            ("arcos", "callflow", "1029.ulaw", "Thank you. Goodbye.", "1029"),
            ("arcos", "callflow", "1351.ulaw", "I'm sorry you are having problems.", "1351"),
            
            # Press keys
            ("arcos", "standard", "PRS1NEU.ulaw", "Press 1", "PRS1NEU"),
            ("arcos", "standard", "PRS3NEU.ulaw", "Press 3", "PRS3NEU"),
            ("arcos", "standard", "PRS7NEU.ulaw", "Press 7", "PRS7NEU"),
            ("arcos", "standard", "PRS9NEU.ulaw", "Press 9", "PRS9NEU"),
            
            # Common words and phrases
            ("arcos", "callflow", "WELCOME.ulaw", "Welcome", "WELCOME"),
            ("arcos", "callflow", "ELECTRIC.ulaw", "electric", "ELECTRIC"),
            ("arcos", "callflow", "CALLOUT.ulaw", "callout", "CALLOUT"),
            ("arcos", "callflow", "AVAILABLE.ulaw", "available", "AVAILABLE"),
            ("arcos", "callflow", "GOODBYE.ulaw", "goodbye", "GOODBYE"),
            ("arcos", "callflow", "THANKYOU.ulaw", "thank you", "THANKYOU"),
            ("arcos", "callflow", "INVALID.ulaw", "invalid entry", "INVALID"),
            ("arcos", "callflow", "1265.ulaw", "Press any key to continue", "1265")
        ]
        
        # Convert to VoiceFile objects
        self.voice_files = []
        for company, folder, file_name, transcript, callflow_id in enhanced_voice_data:
            voice_file = VoiceFile(company, folder, file_name, transcript, callflow_id)
            self.voice_files.append(voice_file)
        
        self._build_indexes()
        print(f"‚úÖ Loaded {len(self.voice_files)} enhanced fallback voice files")

    def _extract_callflow_id(self, file_name: str) -> str:
        """Extract callflow ID from file name following allflows patterns"""
        # Remove extension
        base_name = file_name.replace('.ulaw', '').replace('.wav', '')
        
        # For numeric IDs (e.g., "1677.ulaw" ‚Üí "1677")
        if base_name.isdigit():
            return base_name
        
        # For alphanumeric IDs (e.g., "PRS1NEU.ulaw" ‚Üí "PRS1NEU")
        return base_name

    def _build_indexes(self):
        """Build search indexes for fast voice file lookup"""
        self.transcript_index.clear()
        self.exact_match_index.clear()
        
        for voice_file in self.voice_files:
            # Exact match index
            transcript_clean = voice_file.transcript.lower().strip()
            self.exact_match_index[transcript_clean] = voice_file
            
            # Word-based index for partial matching
            words = re.findall(r'\b\w+\b', transcript_clean)
            for word in words:
                if word not in self.transcript_index:
                    self.transcript_index[word] = []
                self.transcript_index[word].append(voice_file)

    def _find_voice_file_match(self, text: str) -> Optional[VoiceFile]:
        """Find matching voice file using Andres's exact search methodology"""
        text_clean = text.lower().strip()
        
        # First: Try exact match (Andres's preferred method)
        if text_clean in self.exact_match_index:
            return self.exact_match_index[text_clean]
        
        # Second: Try fuzzy matching
        best_match = None
        best_score = 0.0
        
        for voice_file in self.voice_files:
            transcript_clean = voice_file.transcript.lower().strip()
            score = SequenceMatcher(None, text_clean, transcript_clean).ratio()
            
            if score > 0.8 and score > best_score:
                best_score = score
                best_match = voice_file
        
        return best_match

    def _detect_variables_dynamically(self, text: str) -> Dict[str, str]:
        """Dynamically detect variables without hardcoded patterns"""
        variables = {}
        
        # Find all parentheses content
        matches = re.findall(r'\(([^)]+)\)', text)
        
        for match in matches:
            match_lower = match.lower().strip()
            placeholder = f"({match})"
            
            # Dynamic mapping based on content
            if any(word in match_lower for word in ['level', 'location']):
                if '2' in match_lower:
                    variables[placeholder] = '{{level2_location}}'
                else:
                    variables[placeholder] = '{{callout_location}}'
            elif any(word in match_lower for word in ['employee', 'contact', 'name']):
                variables[placeholder] = '{{contact_id}}'
            elif any(word in match_lower for word in ['type', 'callout']):
                variables[placeholder] = '{{callout_type}}'
            elif any(word in match_lower for word in ['reason', 'trouble']):
                variables[placeholder] = '{{callout_reason}}'
            elif any(word in match_lower for word in ['phone', 'number', 'callback']):
                variables[placeholder] = '{{callback_number}}'
            elif any(word in match_lower for word in ['pin', 'code']):
                variables[placeholder] = '{{pin}}'
            elif any(word in match_lower for word in ['message', 'custom']):
                variables[placeholder] = '{{custom_message}}'
            else:
                # Generic variable
                var_name = re.sub(r'[^a-zA-Z0-9_]', '_', match_lower)
                variables[placeholder] = f'{{{{{var_name}}}}}'
        
        return variables

    def _segment_text_like_andres(self, text: str, variables: Dict[str, str]) -> List[str]:
        """ENHANCED: Segment text with ARCOS production phrases for better matching"""
        # Replace variables first
        processed_text = text
        for var_placeholder, var_replacement in variables.items():
            processed_text = processed_text.replace(var_placeholder, var_replacement)
        
        # Clean up HTML and normalize
        processed_text = re.sub(r'<br\s*/?>', ' ', processed_text)
        processed_text = re.sub(r'\s+', ' ', processed_text).strip()
        
        print(f"üîç Enhanced segmenting: '{processed_text}'")
        
        segments = []
        remaining_text = processed_text
        
        # ENHANCED: Priority order with ARCOS production phrases
        while remaining_text and len(segments) < 20:  # Safety limit
            found_match = False
            
            # STEP 1: ARCOS production phrases (from real voice files) + existing effective phrases
            arcos_production_phrases = [
                # From ARCOS CSV (1002, 1005, 1006, 1004, 1009, etc.)
                "press 1 if this is", "press 3 if you need more time to get", 
                "to the phone", "is not home", "invalid entry. please try again",
                "please enter your four digit pin followed by the pound key",
                "please enter your four digit pin", "automated voice response system", 
                "press 2 with", "press 4 to repeat this message",
                
                # Keep existing effective phrases
                "this is an electric callout", "this is an", "this is a", 
                "electric callout", "callout reason", "trouble location",
                "thank you goodbye", "thank you", "goodbye", 
                "press 1", "press 3", "press 7", "press 9",
                "are you available", "available to work", "work this callout",
                "accepted response", "callout decline", "qualified no",
                "employee not home", "press any key"
            ]
            
            # Sort by length (longest first) for better matching
            arcos_production_phrases.sort(key=len, reverse=True)
            
            for phrase in arcos_production_phrases:
                if remaining_text.lower().startswith(phrase.lower()):
                    segments.append(phrase)
                    remaining_text = remaining_text[len(phrase):].strip()
                    remaining_text = re.sub(r'^[.,;:!\?]\s*', '', remaining_text)
                    found_match = True
                    print(f"üéØ ARCOS/production phrase: '{phrase}'")
                    break
            
            if not found_match:
                # STEP 2: Look for complete words in database (minimum 3 characters to avoid letters)
                best_match = None
                best_length = 0
                
                for voice_file in self.voice_files:
                    transcript = voice_file.transcript.strip()
                    # ONLY consider matches of 3+ characters to avoid single letters
                    if (len(transcript) >= 3 and 
                        remaining_text.lower().startswith(transcript.lower())):
                        if len(transcript) > best_length:
                            best_match = voice_file
                            best_length = len(transcript)
                
                if best_match:
                    match_text = remaining_text[:best_length]
                    segments.append(match_text)
                    remaining_text = remaining_text[best_length:].strip()
                    remaining_text = re.sub(r'^[.,;:!\?]\s*', '', remaining_text)
                    found_match = True
                    print(f"‚úÖ Enhanced database match: '{match_text}' -> {best_match.callflow_id}")
            
            if not found_match:
                # STEP 3: Take complete words (avoid breaking into letters)
                words = remaining_text.split()
                if words:
                    first_word = words[0]
                    # Remove punctuation from the word
                    clean_word = re.sub(r'[.,;:!\?]$', '', first_word)
                    # Only add words with 2+ characters to avoid single letters
                    if len(clean_word) >= 2:
                        segments.append(clean_word)
                        remaining_text = ' '.join(words[1:])
                        print(f"üìù Complete word: '{clean_word}'")
                        found_match = True
                    else:
                        # Skip single letters entirely to prevent over-segmentation
                        remaining_text = ' '.join(words[1:])
                        print(f"‚è≠Ô∏è Skipped single letter: '{clean_word}'")
                        found_match = True
                else:
                    break
        
        print(f"üéØ Enhanced segmentation result: {segments}")
        return segments if segments else [processed_text]

    def _generate_voice_prompts(self, segments: List[str], variables: Dict[str, str]) -> Tuple[List[str], List[str]]:
        """ENHANCED: Generate playLog and playPrompt with ARCOS production voice files"""
        play_log = []
        play_prompt = []
        
        print(f"üéµ Enhanced voice generation for: {segments}")
        
        for segment in segments:
            if not segment.strip():
                continue
            
            # Handle variables (existing logic preserved)
            if any(var in segment for var in variables.values()):
                print(f"üîß Processing variable segment: '{segment}'")
                if '{{contact_id}}' in segment:
                    play_log.append("Employee name spoken")
                    play_prompt.append("names:{{contact_id}}")
                elif '{{level2_location}}' in segment or '{{callout_location}}' in segment:
                    play_log.append("location")
                    play_prompt.append(f"location:{segment.replace('.', '')}")
                elif '{{callout_type}}' in segment:
                    play_log.append("type")
                    play_prompt.append("type:{{callout_type}}")
                elif '{{callout_reason}}' in segment:
                    play_log.append("reason")
                    play_prompt.append("reason:{{callout_reason}}")
                elif '{{custom_message}}' in segment:
                    play_log.append("custom message")
                    play_prompt.append("custom:{{custom_message}}")
                else:
                    play_log.append(segment)
                    play_prompt.append(segment)
            else:
                # Look up in real database first (existing logic preserved)
                voice_match = self._find_voice_file_match(segment)
                if voice_match:
                    play_log.append(segment)
                    
                    # Generate proper voice reference based on folder (existing logic)
                    if voice_match.folder == "company":
                        prompt_ref = f"company:{voice_match.callflow_id}"
                    elif voice_match.folder == "standard":
                        prompt_ref = f"standard:{voice_match.callflow_id}"
                    elif voice_match.folder in ["location", "reason", "type"]:
                        prompt_ref = f"{voice_match.folder}:{voice_match.callflow_id}"
                    else:
                        prompt_ref = f"callflow:{voice_match.callflow_id}"
                    
                    play_prompt.append(prompt_ref)
                    print(f"‚úÖ Database match: '{segment}' -> {prompt_ref}")
                else:
                    # ENHANCED: Smart fallbacks with ARCOS production voice files
                    play_log.append(segment)
                    
                    # Enhanced smart fallbacks using real ARCOS voice files + existing fallbacks
                    enhanced_arcos_fallbacks = {
                        # NEW: Real ARCOS production voice files from CSV
                        "press 1 if this is": "callflow:1002",
                        "press 3 if you need more time to get": "callflow:1005", 
                        "to the phone": "callflow:1006",
                        "is not home": "callflow:1004",
                        "invalid entry. please try again": "callflow:1009",
                        "please enter your four digit pin": "callflow:1008",
                        "automated voice response system": "callflow:1001",
                        "press 2 with": "callflow:1003",
                        "press 4 to repeat this message": "callflow:1007",
                        
                        # Common variations and shorter phrases from ARCOS
                        "press 1": "callflow:1002",  # Use ARCOS version
                        "press 3": "callflow:1005",  # Use ARCOS version  
                        "invalid entry": "callflow:1009",  # Use ARCOS version
                        "please enter": "callflow:1008",
                        "not home": "callflow:1004",
                        
                        # Keep existing working fallbacks
                        "this is an": "callflow:1677",
                        "electric callout": "type:electric",
                        "electric": "type:electric",
                        "callout": "callflow:1274",
                        "welcome": "callflow:WELCOME",
                        "thank you": "callflow:THANKYOU",
                        "goodbye": "callflow:GOODBYE",
                        "press 7": "standard:PRS7NEU",
                        "press 9": "standard:PRS9NEU",
                        "press any key": "callflow:1265",
                        "available": "callflow:AVAILABLE"
                    }
                    
                    segment_lower = segment.lower()
                    if segment_lower in enhanced_arcos_fallbacks:
                        prompt_ref = enhanced_arcos_fallbacks[segment_lower]
                        play_prompt.append(prompt_ref)
                        print(f"üéØ ARCOS fallback: '{segment}' -> {prompt_ref}")
                    else:
                        play_prompt.append(f"NEW_VOICE_NEEDED:{segment}")
                        print(f"‚ùì Still needs voice: '{segment}'")
        
        return play_log, play_prompt

    def _parse_mermaid_diagram(self, mermaid_code: str) -> Tuple[List[Dict], List[Dict]]:
        """Parse Mermaid diagram into nodes and connections - FIXED PARSING"""
        lines = [line.strip() for line in mermaid_code.split('\n') if line.strip()]
        
        nodes = []
        connections = []
        node_texts = {}
        
        # Join all lines to handle multiline node definitions
        full_text = ' '.join(lines)
        
        # Extract node definitions with better regex patterns
        # Pattern for rectangular nodes: A["text content"]
        rect_pattern = r'([A-Z]+)\s*\[\s*"([^"]+)"\s*\]'
        # Pattern for diamond nodes: A{"text content"}  
        diamond_pattern = r'([A-Z]+)\s*\{\s*"([^"]+)"\s*\}'
        
        # Find all rectangular nodes
        for match in re.finditer(rect_pattern, full_text):
            node_id, node_text = match.groups()
            # Clean HTML tags and normalize
            node_text = re.sub(r'<br\s*/?>', ' ', node_text)
            node_text = re.sub(r'<[^>]+>', '', node_text)
            node_text = re.sub(r'\s+', ' ', node_text).strip()
            node_texts[node_id] = node_text
            print(f"üì¶ Found rectangular node: {node_id} = '{node_text[:50]}...'")
        
        # Find all diamond nodes (decisions)
        for match in re.finditer(diamond_pattern, full_text):
            node_id, node_text = match.groups()
            # Clean HTML tags and normalize
            node_text = re.sub(r'<br\s*/?>', ' ', node_text)
            node_text = re.sub(r'<[^>]+>', '', node_text)
            node_text = re.sub(r'\s+', ' ', node_text).strip()
            node_texts[node_id] = node_text
            print(f"üíé Found diamond node: {node_id} = '{node_text[:50]}...'")
        
        # Extract connections with improved parsing
        # Handle both quoted and unquoted labels
        connection_patterns = [
            r'([A-Z]+)\s*-->\s*\|"([^"]+)"\|\s*([A-Z]+)',  # |"quoted label"|
            r'([A-Z]+)\s*-->\s*\|([^|]+)\|\s*([A-Z]+)',    # |unquoted label|
            r'([A-Z]+)\s*-->\s*([A-Z]+)'                   # direct connection
        ]
        
        for line in lines:
            if '-->' in line:
                # Try each pattern
                for pattern in connection_patterns:
                    match = re.search(pattern, line)
                    if match:
                        groups = match.groups()
                        if len(groups) == 3:
                            source, label, target = groups
                        else:
                            source, target = groups
                            label = ''
                        
                        connections.append({
                            'source': source,
                            'target': target,
                            'label': label.strip() if label else ''
                        })
                        print(f"üîó Found connection: {source} -> {target} ('{label}')")
                        break  # Found a match, stop trying other patterns
        
        # Create node objects
        for node_id, text in node_texts.items():
            # Determine node type from content and shape
            node_type = self._determine_node_type(text)
            
            nodes.append({
                'id': node_id,
                'text': text,
                'type': node_type
            })
        
        print(f"‚úÖ Parsed {len(nodes)} nodes and {len(connections)} connections")
        return nodes, connections

    def _determine_node_type(self, text: str) -> NodeType:
        """Determine node type from text content - IMPROVED DETECTION"""
        text_lower = text.lower()
        
        # Welcome nodes - typically first nodes with greeting
        if any(phrase in text_lower for phrase in ["welcome", "this is an", "this is a", "automated"]):
            return NodeType.WELCOME
        
        # PIN entry nodes
        if any(phrase in text_lower for phrase in ["pin", "enter", "digits"]) and not "invalid" in text_lower:
            return NodeType.PIN_ENTRY
        
        # Availability questions - specific pattern
        if "available" in text_lower and any(phrase in text_lower for phrase in ["work", "callout", "press 1", "press 3"]):
            return NodeType.AVAILABILITY
        
        # Response/action nodes
        if any(phrase in text_lower for phrase in ["accepted", "decline", "response", "recorded"]):
            return NodeType.RESPONSE
        
        # Goodbye/disconnect nodes
        if any(phrase in text_lower for phrase in ["goodbye", "thank you", "disconnect"]):
            return NodeType.GOODBYE
        
        # Error/problem nodes
        if any(phrase in text_lower for phrase in ["invalid", "error", "problem", "try again"]):
            return NodeType.ERROR
        
        # Sleep/wait nodes
        if any(phrase in text_lower for phrase in ["more time", "continue", "press any key"]):
            return NodeType.SLEEP
        
        # Decision nodes - contain questions or simple yes/no choices
        if any(phrase in text_lower for phrase in ["?", "yes", "no", "correct"]) or len(text.split()) <= 5:
            return NodeType.DECISION
        
        # Default to action
        return NodeType.ACTION

    def _generate_meaningful_label(self, node_text: str, node_type: NodeType, node_id: str, all_nodes: List[Dict] = None) -> str:
        """Generate meaningful labels like allflows LITE (NOT A, B, C) - IMPROVED"""
        
        if node_text:
            text_lower = node_text.lower()
            
            # Welcome/greeting nodes
            if "welcome" in text_lower or "this is" in text_lower or node_type == NodeType.WELCOME:
                return "Live Answer"
            
            # PIN entry
            if "pin" in text_lower and ("enter" in text_lower or "type" in text_lower or "digits" in text_lower):
                return "Enter PIN"
            
            # Availability questions
            if "available" in text_lower and "work" in text_lower:
                return "Available For Callout"
            
            # Response actions
            if "accept" in text_lower and "response" in text_lower:
                return "Accept"
            elif "decline" in text_lower:
                return "Decline"
            elif "not home" in text_lower:
                return "Not Home"
            elif "qualified" in text_lower:
                return "Qualified No"
            
            # Sleep/wait
            if ("more time" in text_lower or "continue" in text_lower or "press any key" in text_lower) and "message" in text_lower:
                return "Sleep"
            
            # Goodbye
            if "goodbye" in text_lower or ("thank you" in text_lower and "goodbye" in text_lower):
                return "Goodbye"
            elif "disconnect" in text_lower:
                return "Disconnect"
            
            # Error/problems
            if "invalid" in text_lower and "entry" in text_lower:
                return "Invalid Entry"
            elif "problem" in text_lower or "error" in text_lower:
                return "Problems"
            
            # Callout information nodes
            if "electric callout" in text_lower:
                return "Electric Callout"
            elif "callout reason" in text_lower:
                return "Callout Reason"
            elif "trouble location" in text_lower:
                return "Trouble Location"
            elif "custom message" in text_lower:
                return "Custom Message"
            
            # Decision nodes (short questions)
            if node_type == NodeType.DECISION or "?" in node_text:
                if "correct" in text_lower and "pin" in text_lower:
                    return "Check PIN"
                elif "this is employee" in text_lower or "employee" in text_lower:
                    return "Verify Employee"
                elif len(node_text.split()) <= 3:
                    return node_text.title()
            
            # Fallback: Generate from first few words
            words = re.findall(r'\b[A-Za-z]+\b', node_text)
            if words:
                # Take first 2-3 meaningful words
                meaningful_words = [w for w in words[:3] if len(w) > 2 and w.lower() not in ['the', 'and', 'for', 'you', 'this', 'that']]
                if meaningful_words:
                    return ' '.join(word.capitalize() for word in meaningful_words)
        
        # Fallback based on node ID patterns
        id_mapping = {
            'A': 'Live Answer',
            'B': 'Verify Employee', 
            'C': 'Sleep',
            'D': 'Not Home',
            'E': 'Check Input',
            'F': 'Invalid Entry',
            'G': 'Check PIN',
            'H': 'Electric Callout',
            'I': 'Callout Reason',
            'J': 'Trouble Location',
            'K': 'Custom Message',
            'L': 'Available For Callout',
            'M': 'Accept',
            'N': 'Decline',
            'O': 'Qualified No',
            'P': 'Goodbye',
            'Q': 'Disconnect'
        }
        if node_id and node_id in id_mapping:
            return id_mapping[node_id]
        
        # Last resort: Use node type
        return f"{node_type.value.replace('_', ' ').title()} {node_id}"

    def _create_ivr_node(self, node: Dict, connections: List[Dict], label: str, node_id_to_label: Dict[str, str] = None) -> Dict[str, Any]:
        """Create IVR node following allflows LITE patterns"""
        text = node['text']
        node_type = node['type']
        
        # Dynamic variable detection
        variables = self._detect_variables_dynamically(text)
        
        # Segment text like Andres does manually
        segments = self._segment_text_like_andres(text, variables)
        
        # Generate voice prompts using real database
        play_log, play_prompt = self._generate_voice_prompts(segments, variables)
        
        # Create base node following allflows property order
        ivr_node = {'label': label}
        
        # Add playLog or log
        if len(play_log) > 1:
            ivr_node['playLog'] = play_log
        elif play_log:
            ivr_node['log'] = play_log[0]
        
        # Add playPrompt
        if len(play_prompt) > 1:
            ivr_node['playPrompt'] = play_prompt
        elif play_prompt:
            ivr_node['playPrompt'] = play_prompt[0]
        
        # Add interaction logic based on node type
        if node_type in [NodeType.WELCOME, NodeType.AVAILABILITY, NodeType.DECISION]:
            self._add_input_logic(ivr_node, connections, node, node_id_to_label)
        elif node_type == NodeType.RESPONSE:
            self._add_response_logic(ivr_node, label)
        elif len(connections) == 1:
            # Simple goto
            target_id = connections[0]['target']
            if node_id_to_label and target_id in node_id_to_label:
                target_label = node_id_to_label[target_id]
            else:
                target_label = self._generate_meaningful_label("", NodeType.ACTION, target_id)
            ivr_node['goto'] = target_label
        
        return ivr_node

    def _add_input_logic(self, ivr_node: Dict, connections: List[Dict], node: Dict, node_id_to_label: Dict[str, str] = None):
        """Add getDigits and branch logic - IMPROVED LABEL PARSING"""
        if not connections:
            return
        
        # Determine valid choices from connection labels with better parsing
        valid_choices = []
        branch_map = {}
        
        for conn in connections:
            label = conn.get('label', '').lower()
            target = conn['target']
            
            # Use the pre-computed label if available
            if node_id_to_label and target in node_id_to_label:
                target_label = node_id_to_label[target]
            else:
                target_label = self._generate_meaningful_label("", NodeType.ACTION, target)
            
            print(f"üîÄ Processing connection label: '{label}' -> {target} ({target_label})")
            
            # Extract digit from various label formats
            if re.search(r'\b1\b', label) or 'press 1' in label:
                valid_choices.append('1')
                branch_map['1'] = target_label
            elif re.search(r'\b3\b', label) or 'press 3' in label:
                valid_choices.append('3')
                branch_map['3'] = target_label
            elif re.search(r'\b7\b', label) or 'press 7' in label:
                valid_choices.append('7')
                branch_map['7'] = target_label
            elif re.search(r'\b9\b', label) or 'press 9' in label:
                valid_choices.append('9')
                branch_map['9'] = target_label
            elif re.search(r'\b0\b', label) or 'press 0' in label:
                valid_choices.append('0')
                branch_map['0'] = target_label
            elif any(phrase in label for phrase in ['no input', 'timeout', 'none']):
                branch_map['none'] = target_label
            elif any(phrase in label for phrase in ['invalid', 'error', 'retry']):
                branch_map['error'] = target_label
            elif any(phrase in label for phrase in ['yes', 'correct']):
                branch_map['yes'] = target_label  # For yes/no decisions
            elif any(phrase in label for phrase in ['no', 'incorrect']):
                branch_map['no'] = target_label   # For yes/no decisions
            else:
                # Default connection or self-loop
                if conn['source'] == conn['target']:
                    # Self-loop for retry
                    continue
                else:
                    # Direct connection without input
                    if not branch_map:
                        ivr_node['goto'] = target_label
                        return
        
        # Add getDigits configuration
        if valid_choices:
            ivr_node['getDigits'] = {
                'numDigits': 1,
                'maxTime': 7,
                'validChoices': '|'.join(sorted(set(valid_choices))),
                'errorPrompt': 'callflow:1009'
            }
            
            # Add error handling if not already specified
            if 'error' not in branch_map:
                branch_map['error'] = 'Problems'
            if 'none' not in branch_map and 'timeout' not in branch_map:
                branch_map['none'] = 'Problems'
            
            ivr_node['branch'] = branch_map
            print(f"‚úÖ Added input logic: choices={valid_choices}, branches={branch_map}")
        elif branch_map:
            # Yes/no style decision without numeric input
            ivr_node['branch'] = branch_map
            print(f"‚úÖ Added decision logic: branches={branch_map}")
        else:
            print(f"‚ö†Ô∏è No input logic detected for connections: {[c['label'] for c in connections]}")

    def _add_response_logic(self, ivr_node: Dict, label: str):
        """Add gosub for response handling like allflows LITE"""
        if 'accept' in label.lower():
            ivr_node['gosub'] = ['SaveCallResult', 1001, 'Accept']
        elif 'decline' in label.lower():
            ivr_node['gosub'] = ['SaveCallResult', 1002, 'Decline']
        elif 'not home' in label.lower():
            ivr_node['gosub'] = ['SaveCallResult', 1006, 'NotHome']
        else:
            ivr_node['goto'] = 'Goodbye'

    def convert_mermaid_to_ivr(self, mermaid_code: str) -> Tuple[List[Dict[str, Any]], List[str]]:
        """Main conversion method - PRODUCTION READY WITH DEBUGGING"""
        notes = []
        
        try:
            print(f"üöÄ Starting conversion of Mermaid diagram...")
            print(f"üìù Input length: {len(mermaid_code)} characters")
            
            # Parse Mermaid diagram
            nodes, connections = self._parse_mermaid_diagram(mermaid_code)
            notes.append(f"Parsed {len(nodes)} nodes and {len(connections)} connections")
            
            if not nodes:
                notes.append("‚ùå No nodes found in diagram - check Mermaid syntax")
                print("‚ùå PARSING FAILED - No nodes extracted")
                print("üìã Input preview:")
                for i, line in enumerate(mermaid_code.split('\n')[:10]):
                    print(f"  {i+1}: {line}")
                return self._create_fallback_flow(), notes
            
            print(f"‚úÖ Successfully parsed {len(nodes)} nodes")
            
            # Create a mapping of node IDs to meaningful labels
            node_id_to_label = {}
            used_labels = set()
            
            for node in nodes:
                base_label = self._generate_meaningful_label(node['text'], node['type'], node['id'], nodes)
                
                # Handle duplicate labels by adding suffix
                final_label = base_label
                counter = 1
                while final_label in used_labels:
                    final_label = f"{base_label} {counter}"
                    counter += 1
                
                node_id_to_label[node['id']] = final_label
                used_labels.add(final_label)
                print(f"üè∑Ô∏è {node['id']} -> '{final_label}' ({node['type'].value})")
            
            # Generate IVR nodes with meaningful labels
            ivr_nodes = []
            
            for node in nodes:
                print(f"\nüîÑ Processing node {node['id']}: {node['text'][:50]}...")
                
                # Get the meaningful label
                label = node_id_to_label[node['id']]
                
                # Get connections for this node
                node_connections = [c for c in connections if c['source'] == node['id']]
                print(f"üîó Found {len(node_connections)} outgoing connections")
                
                # Create IVR node with node mapping for better branch labels
                ivr_node = self._create_ivr_node(node, node_connections, label, node_id_to_label)
                ivr_nodes.append(ivr_node)
                
                notes.append(f"Generated node: {label}")
                print(f"‚úÖ Generated IVR node: {label}")
            
            # Add standard termination nodes if not present
            if not any(node.get('label') == 'Problems' for node in ivr_nodes):
                ivr_nodes.append({
                    'label': 'Problems',
                    'log': 'Error handler - invalid input or system error',
                    'playPrompt': 'callflow:1351',
                    'goto': 'Goodbye'
                })
                notes.append("Added standard 'Problems' error handler")
            
            if not any(node.get('label') == 'Goodbye' for node in ivr_nodes):
                ivr_nodes.append({
                    'label': 'Goodbye',
                    'log': 'Thank you goodbye',
                    'playPrompt': 'callflow:1029'
                })
                notes.append("Added standard 'Goodbye' termination")
            
            notes.append(f"‚úÖ Generated {len(ivr_nodes)} production-ready IVR nodes")
            print(f"üéâ CONVERSION SUCCESSFUL - Generated {len(ivr_nodes)} nodes")
            
            return ivr_nodes, notes
            
        except Exception as e:
            error_msg = f"‚ùå Conversion failed: {str(e)}"
            notes.append(error_msg)
            print(error_msg)
            import traceback
            traceback.print_exc()
            return self._create_fallback_flow(), notes

    def _create_fallback_flow(self) -> List[Dict[str, Any]]:
        """Create fallback flow for errors"""
        return [
            {
                'label': 'Problems',
                'log': 'Error handler',
                'playPrompt': 'callflow:1351',
                'goto': 'Goodbye'
            },
            {
                'label': 'Goodbye',
                'log': 'Thank you goodbye',
                'playPrompt': 'callflow:1029'
            }
        ]

# Main function for the app
def convert_mermaid_to_ivr(mermaid_code: str, uploaded_csv_file=None) -> Tuple[List[Dict[str, Any]], List[str]]:
    """Production-ready conversion function with optional CSV upload"""
    converter = ProductionIVRConverter(uploaded_csv_file)
    return converter.convert_mermaid_to_ivr(mermaid_code)